#Create output directory
DIR='Mason_output'

#Set path to human genome


#Read in run accession IDs from txt file.
with open ("Bamids.txt") as f:
    ids=f.read().splitlines()


chr_list = list(range(1, 23))




rule all:
        input:
                expand("{wd}/{sample}/All.{sample}.vcf.gz",sample=ids,wd=DIR)


rule var_call:
        input:
                "/ocean/projects/mcb200036p/shared/02-AlignedData/{sample}_all-reads/{sample}_all-reads_Aligned.sortedByCoord_sorted.out.bam"
        output:
                "{wd}/{sample}/Chr{chr}.final.vcf.gz"
        shell:
                """
                
                

            
                samtools view -b {input} {wildcards.chr}  > {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.bam



                gatk MarkDuplicates \
                    I= {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.bam \
                    O= {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.MarkDup.bam \
                    CREATE_INDEX= true \
                    METRICS_FILE= {wildcards.wd}/{wildcards.sample}/marked_dup_metrics.{wildcards.chr}.txt \
                    VALIDATION_STRINGENCY= SILENT
                rm {wildcards.wd}/{wildcards.sample}/*Chr{wildcards.chr}.bam

                gatk AddOrReplaceReadGroups \
                    I= {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.MarkDup.bam \
                    O= {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.Grouped.bam \
                    RGSM= sample \
                    RGLB= lib \
                    RGPL= plat \
                    RGPU= plat
                rm {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.MarkDup*

                gatk SplitNCigarReads \
                    -I {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.Grouped.bam  \
                    -O {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.final.bam \
                    -R data/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna
                rm {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.Grouped.bam



                gatk --java-options "-Xmx20g" HaplotypeCaller \
                   -I {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.final.bam \
                   -O {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.vcf.gz \
                   -R data/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \
                   -L data/Chr{wildcards.chr}_SNPs.interval_list \
                   -ERC GVCF \
                   --native-pair-hmm-threads 8
                rm {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.final*


                gunzip -c {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.vcf.gz |  grep -v "0/0:0:0:0:0,0,0" | bgzip > {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.final.vcf.gz
                rm {wildcards.wd}/{wildcards.sample}/*Chr{wildcards.chr}.vcf.gz

                bcftools index -t {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.final.vcf.gz
                """
rule Genotype:
    input: "{wd}/{sample}/Chr{chr}.final.vcf.gz"
    output:"{wd}/{sample}/Chr{chr}.final2.vcf.gz"

    shell:
        """
        gatk --java-options "-Xmx10g" GenotypeGVCFs \
        -R data/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \
        -V {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.final.vcf.gz \
        -O {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.vcf.gz \
        --include-non-variant-sites
        rm {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.final.vcf.gz*

        gatk --java-options "-Xmx10g" VariantFiltration \
        -R data/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \
        -V {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.vcf.gz \
        -O {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.filtered.vcf.gz \
        --filter-expression "DP < 5.0" \
        --filter-name "filter_DP" \
        --filter-expression "MQ < 40.0" \
        --filter-name "filter_MQ" \
        --filter-expression "FS > 60.0" \
        --filter-name "filter_FS" \
        --filter-expression "MQRankSum < -12.5" \
        --filter-name "filter_MQRankSum" \
        --filter-expression "ReadPosRankSum < -8.0" \
        --filter-name "filter_ReadPosRankSum" \
        --filter-expression "QD < 2.0" \
        --filter-name "filter_QD"
        rm {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.vcf.gz*


        gatk --java-options "-Xmx10g" SelectVariants \
        -R data/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \
        -V {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.filtered.vcf.gz  \
        -O {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.final2.vcf.gz \
        --exclude-filtered true \
        --select-type-to-exclude INDEL

        rm {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.filtered.vcf.gz*
        """




rule compare:
    input: "{wd}/{sample}/Chr{chr}.final2.vcf.gz"
    output: "{wd}/{sample}/Chr{chr}.{sample}.vcf.gz"
    shell:
        """

        gunzip -c  {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.final2.vcf.gz | grep -v  "\./\." | bgzip > {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.final2.filtered.vcf.gz
        bcftools index -t {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.final2.filtered.vcf.gz

        rm {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.final2.vcf.gz*

        #all sites with matching positions. Will result in all 0/0 calls that match and will have 0/1 and 1/1 which also match but some will be the wronf alt allele.

        tabix -h -T data/Chr{wildcards.chr}_SNPs.interval_list {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.final2.filtered.vcf.gz | bgzip  > {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.comm_pos.vcf.gz
        bcftools index -t {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.comm_pos.vcf.gz


        rm {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.final2.filtered.vcf.gz*

        #Make an index file of comm_pos.vcf.gz. Handels blank vcfs
        gunzip -c {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.comm_pos.vcf.gz | {{ grep -v "#" || true; }} | awk -F'\t' -v OFS='\t' '{{print $1,$2}}' | cat > {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.comm_pos.interval_list

        #Extract positions from 1KGP
        tabix -h -T {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.comm_pos.interval_list  data/Chr{wildcards.chr}_SNPs.vcf.gz | bgzip   > {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}1000.vcf.gz
        bcftools index -t {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}1000.vcf.gz

        #Match only on positions that have the same allele.
        bcftools isec -c none {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.comm_pos.vcf.gz {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}1000.vcf.gz --output-type z --threads 8 -p {wildcards.wd}/{wildcards.sample}/dir{wildcards.chr}
        #0000.vcf.gz is records private to  comm_pos.vcf.gz.They will be 0/0 calls that are true matches and 1/1 and 0/1 calls with wrong alt allele. Remove 0/0 and same others as an index list.
        gunzip -c {wildcards.wd}/{wildcards.sample}/dir{wildcards.chr}/0000.vcf.gz | grep -v "0/0" | {{ grep -v "#" || true; }} | awk -F'\t' -v OFS='\t' '{{print $1,$2}}' | cat > {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}List

        #If List is not empty, then remove unwanted SNPs, else remove nothing.

        if test -s {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}List ; then
                bcftools view -T ^{wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}List {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}1000.vcf.gz --output-type z --threads 8 > {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.1KG.vcf.gz
                bcftools view -T ^{wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}List {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.comm_pos.vcf.gz --output-type z --threads 8 > {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.unk.vcf.gz
        else
                mv {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}1000.vcf.gz {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.1KG.vcf.gz
                mv {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.comm_pos.vcf.gz {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.unk.vcf.gz
        fi

        rm -r  {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.comm_pos.interval_list  {wildcards.wd}/{wildcards.sample}/dir{wildcards.chr} {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}1000.vcf.gz* {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.comm_pos.vcf.gz* {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}List

        #Use List to remove unmatched positions from data comtaining all matches 0/0 1/0 1/1.

        bcftools index -t {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.unk.vcf.gz
        bcftools index -t {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.1KG.vcf.gz
        #Combine 1KGP with sample to have ancestry infered

        bcftools merge {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.1KG.vcf.gz {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.unk.vcf.gz  --output-type z --threads 8 > {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.{wildcards.sample}.vcf.gz
        bcftools index -t {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.{wildcards.sample}.vcf.gz

        rm {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.1KG.vcf.gz* {wildcards.wd}/{wildcards.sample}/Chr{wildcards.chr}.unk.vcf.gz*

        """

rule concat:
    input: expand("{wd}/{sample}/Chr{chr}.{sample}.vcf.gz",sample=ids,chr=chr_list,wd=DIR)
    output: "{wd}/{sample}/All.{sample}.vcf.gz"
    shell:
        "bcftools concat {wildcards.wd}/{wildcards.sample}/*{wildcards.sample}.vcf.gz --output-type z --threads 8 > {wildcards.wd}/{wildcards.sample}/All.{wildcards.sample}.vcf.gz"

